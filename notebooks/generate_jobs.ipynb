{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall performance of module detection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# sys.path.insert(0,os.path.abspath(\"../lib/\"))\n",
    "\n",
    "import json\n",
    "\n",
    "from util import JSONExtendedEncoder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import itertools\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "\n",
    "conf_folder = \"conf/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = 1\n",
    "# N_JOBS = mp.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "method_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert method_name is not None, \"You have to specify a method_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running a method on different parameter settings and datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you downloaded the results from zenodo, you don't need to rerun this for \"dummy\", \"agglom\", \"ica_zscore\", \"spectral_biclust\" and \"meanshift\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will explore the parameters of a module detection method on every dataset using a grid-search approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run your own method, you should wrap it into a python function and add its parameters to `conf/paramexplo_blueprints.py`. We will show the whole workflow here for a \"dummy\"  (but fast) clustering method, which will simply group genes randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every module detection method is wrapped in a python function (see `scripts/moduledetection.py`)\n",
    "\n",
    "Because module detection methods usually take a while to run, we generate the files necessary to run a method on the several parameter settings and datasets here. These can then be easily called from the commandline, for example on a computer cluster or locally using GNU `parallel`.\n",
    "\n",
    "This function will be called by scripts/moduledetection.py , which will save the modules in the correct format along with additional run information (such as running times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets to run\n",
    "datasetnames = [\n",
    "    \"ecoli_colombos\",\n",
    "    \"ecoli_dream5\",\n",
    "    \"yeast_gpl2529\",\n",
    "    \"yeast_dream5\",\n",
    "    \"synth_ecoli_regulondb\",\n",
    "    \"synth_yeast_macisaac\",\n",
    "    \"human_tcga\",\n",
    "    \"human_gtex\",\n",
    "    \"human_seek_gpl5175\",\n",
    "    \"ecoli_precise2\"\n",
    "]\n",
    "\n",
    "# choose the method to evaluate\n",
    "# method_name = \"agglom_pearson_abs\" # use the dummy method to check if everything works correctly\n",
    "# method_name = \"agglom\" # this method runs very fast, and has the best performance among clustering methods\n",
    "# method_name = \"ica_zscore\" # this method runs very slow, but has approx. the highest performance in the benchmark\n",
    "# method_name = \"spectral_biclust\" # top biclustering method\n",
    "# method_name = \"meanshift\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add your own method, create a function with \"your_method_name\" in the `lib/clustering.py` file (or any other file as long as it's imported in `scripts/moduledetection.py`.\n",
    "This function should accept an `E` object (which is a dataframe with genes in columns) and any additional parameters\n",
    "Then add reasonable parameter setting of your method to `conf/paramexplo_blueprints.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method_name = \"your_method_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramexplo_blueprints.py stores for every method the parameters which will be varied using a grid-search approach.\n",
    "%run ../conf/paramexplo_blueprints.py\n",
    "methodblueprint = blueprints[method_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methodblueprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate different parameter settings using a grid-search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_folder = \"conf/paramexplo/\" + method_name + \"/\"\n",
    "if os.path.exists(\"../\" + params_folder):\n",
    "    shutil.rmtree(\"../\" + params_folder)\n",
    "os.makedirs(\"../\" + params_folder)\n",
    "\n",
    "methodsettings = []\n",
    "method_locations = []\n",
    "i = 0\n",
    "for dynparam_combination in list(itertools.product(*[methodblueprint[\"dynparams\"][param] for param in sorted(methodblueprint[\"dynparams\"].keys())])):\n",
    "    method = {\"params\":{}}\n",
    "    method[\"params\"] = methodblueprint[\"staticparams\"].copy()\n",
    "    method[\"params\"].update(dict(zip(sorted(methodblueprint[\"dynparams\"].keys()), dynparam_combination)))\n",
    "    method[\"location\"] = params_folder + str(i) + \".json\"\n",
    "    method[\"seed\"] = 0\n",
    "\n",
    "    methodsettings.append(method)\n",
    "\n",
    "    json.dump(method, open(\"../\" + method[\"location\"], \"w\"), cls=JSONExtendedEncoder)\n",
    "\n",
    "    method_locations.append(method[\"location\"])\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine the different parameter settings and datasets. Then generate the different python commands to run every parameter setting and dataset in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_name = \"paramexplo/{method_name}\".format(method_name = method_name)\n",
    "settings = []\n",
    "for datasetname in datasetnames:\n",
    "    for setting_ix, methodsetting in enumerate(methodsettings):\n",
    "        settingid = datasetname + \"_\" + str(setting_ix)\n",
    "        settings.append({\n",
    "            \"dataset_location\":\"conf/datasets/\" + datasetname + \".json\",\n",
    "            \"dataset_name\":datasetname,\n",
    "            \"method_location\":methodsetting[\"location\"],\n",
    "            \"output_folder\":\"results/\" + methodblueprint[\"type\"] + \"/{settings_name}/{settingid}/\".format(settings_name=settings_name, settingid=settingid),\n",
    "            \"settingid\":settingid\n",
    "        })\n",
    "json.dump(settings, open(\"../conf/settings/{settings_name}.json\".format(settings_name=settings_name), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dataset = pd.DataFrame([dict(settingid=setting[\"settingid\"], **json.load(open(\"../\" + setting[\"dataset_location\"]))[\"params\"]) for setting in settings])\n",
    "settings_method = pd.DataFrame([dict(settingid=setting[\"settingid\"], **json.load(open(\"../\" + setting[\"method_location\"]))[\"params\"]) for setting in settings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = \"\"\n",
    "for i, setting in enumerate(settings):\n",
    "    #commands += \"python scripts/moduledetection.py {method_location} {dataset_location} {output_folder} 0 test\\n\".format(**setting)\n",
    "    commands += \"python3 scripts/\" + methodblueprint[\"type\"] + \".py {method_location} {dataset_location} {output_folder}\\n\".format(**setting)\n",
    "\n",
    "commands_location = \"tmp/{settings_name}.txt\".format(**locals())\n",
    "os.makedirs(\"../\" + os.path.dirname(commands_location), exist_ok=True)\n",
    "with open(\"../\" + commands_location, \"w\") as outfile:\n",
    "    outfile.write(commands)\n",
    "commands_location = \"tmp/{settings_name}.txt\".format(**locals())\n",
    "os.makedirs(os.path.dirname(\"../tmp/\" + commands_location), exist_ok=True)\n",
    "with open(\"../tmp/\" + commands_location, \"w\") as outfile:\n",
    "    outfile.write(commands)\n",
    "    \n",
    "#script_location = generate_batchcode(commands_location, settings_name, len(settings), {\"memory\":\"10G\", \"numcores\":1}, \"biclust_comp2\")\n",
    "\n",
    "# this command can be used on most linux computers to run the different parameter settings in parallel\n",
    "print(\"Run the following command:\\nparallel -j 4 -a \" + commands_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "jupytext": {
   "cell_metadata_filter": "all,-execution,-papermill,-trusted",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.13.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
